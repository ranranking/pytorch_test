{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from util import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr = pd.read_csv('./sun397_train_lt.txt', header=None, sep=' ')\n",
    "\n",
    "# class_names = {}\n",
    "\n",
    "# for lab in tr[1].unique():\n",
    "#     temp = tr.loc[tr[1] == lab].iloc[0, 0]\n",
    "#     class_name = temp.split('/')[-2]\n",
    "#     class_names[lab] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './log'\n",
    "DATASET = 'plain'\n",
    "MODEL_ID = 'test'\n",
    "DATALOADER_WORKERS = 4\n",
    "LEARNING_RATE = 0.01\n",
    "LR_DECAY_FACTOR = 0.1\n",
    "LR_DECAY_EPOCHS = 10\n",
    "DROPOUT = True\n",
    "DROPOUT_RATE = 0.5\n",
    "MOMENTUM = 0.9\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "DISPLAY_STEP = 10\n",
    "NUM_CLASSES = 397\n",
    "MULTI_VIEW_NUMBER = 5\n",
    "\n",
    "if not os.path.isdir(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sun_dataset_test (torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__ (self, txt_file, multi_view_time, transform):\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(txt_file, header=None, sep=' ')\n",
    "        self.transform = transform\n",
    "        self.multi_view_time = multi_view_time\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        \n",
    "        image = Image.open(self.df.iloc[idx, 0])\n",
    "        label = self.df.iloc[idx, 1] - 1\n",
    "#         image_dir = self.df.iloc[idx, 0]\n",
    "        \n",
    "        mult_view_images = torch.tensor([], dtype=torch.float32)\n",
    "\n",
    "        for i in range(self.multi_view_time):\n",
    "            image_transform = self.transform(image).unsqueeze(0)\n",
    "            mult_view_images = torch.cat((mult_view_images, image_transform), 0)\n",
    "            \n",
    "        return mult_view_images, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.RandomResizeCrop(224)\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sun_dataset_test(txt_file='./sun397_test_lt.txt', transform=data_transform, multi_view_time=MULTI_VIEW_NUMBER)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=DATALOADER_WORKERS)\n",
    "dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, l = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5, 3, 224, 224])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = i.reshape((-1, i.shape[2], i.shape[3], i.shape[4]))\n",
    "\n",
    "# def imshow(inp, title=None):\n",
    "#     \"\"\"Imshow for Tensor.\"\"\"\n",
    "#     inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "#     plt.imshow(inp)\n",
    "#     if title is not None:\n",
    "#         plt.title(title)\n",
    "\n",
    "# img_grid = torchvision.utils.make_grid(j[0:5])\n",
    "\n",
    "# imshow(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./log/model_combine_base_lr_70_ep_150_caffe_drop_0.5_dim_4096_checkpoint.pth.tar')\n",
    "DROPOUT = True\n",
    "DROPOUT_RATE = 0.5\n",
    "FC_ADD_DIM = 4096\n",
    "BIAS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Model using dropout.\n",
      "Bias is True\n",
      "Intermediate fc dimension is: 4096\n",
      "Dropout rate is: 0.500000\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet152(pretrained=False)\n",
    "# Freeze all layers\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print('Done.')    \n",
    "\n",
    "if DROPOUT:\n",
    "    print('Model using dropout.')\n",
    "    resnet = MyResNet(resnet, NUM_CLASSES, DROPOUT_RATE, FC_ADD_DIM, bias=BIAS)\n",
    "else:\n",
    "    print('Model not using dropout.')\n",
    "    # Reset the fc layer\n",
    "    num_features = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(num_features, NUM_CLASSES)\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [05:30<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_micro: 0.490, accuracy_macro: 0.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "running_correct_total = 0\n",
    "\n",
    "class_correct = torch.tensor([0. for i in range(NUM_CLASSES)])\n",
    "class_total = torch.tensor([0. for i in range(NUM_CLASSES)])\n",
    "\n",
    "# Iterate over data\n",
    "for inputs, labels in tqdm(dataloader):\n",
    "    \n",
    "    # Reshape inputs into a 4D tensor\n",
    "    inputs = inputs.reshape((-1, inputs.shape[2], inputs.shape[3], inputs.shape[4]))\n",
    "\n",
    "    # To device\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    # Forward\n",
    "    # If on training phase, enable gradients\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        logits = model(inputs)\n",
    "        \n",
    "        # Adding multiview dimension into logits\n",
    "        logits = logits.reshape((-1, MULTI_VIEW_NUMBER, NUM_CLASSES))\n",
    "        \n",
    "        # Mean over multiview dimension\n",
    "        logits = logits.mean(dim=1)\n",
    "        \n",
    "        _, preds = torch.max(logits, 1)\n",
    "    \n",
    "    # Record correct predictions\n",
    "    correct_tensor = (preds == labels).squeeze()\n",
    "    running_correct_total += correct_tensor.sum().item()\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += correct_tensor[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "        \n",
    "test_acc_mic = running_correct_total / dataset_size\n",
    "test_acc_mac = (class_correct / class_total).mean().item()\n",
    "\n",
    "print('accuracy_micro: %.3f, accuracy_macro: %.3f' \n",
    "      % (test_acc_mic, test_acc_mac))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_base_lr_70_ep_150_caffe_drop_0.5_dim_4096 0.47\n",
    "\n",
    "plain_base_lr_60_ep_150_caffe_drop_0.5_dim_4096 0.467\n",
    "\n",
    "plain_base_lr_100_ep_150_caffe_drop_0.5_dim_4096 0.471\n",
    "\n",
    "combine_base_lr_70_ep_150_caffe_drop_0.5_dim_4096 0.487\n",
    "\n",
    "combine_aug_sm_base_lr_100_ep_150_caffe_drop_0.5_dim_4096 0.492\n",
    "\n",
    "combine_base_lr_70_ep_150_caffe_drop_0.5_dim_4096 0.488"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
