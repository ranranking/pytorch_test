{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from util import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('./combine_txt/sun397_train_lt.txt', header=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {}\n",
    "class_num = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in tr[1].unique():\n",
    "    temp = tr.loc[tr[1] == lab].iloc[0, 0]\n",
    "    class_name = temp.split('/')[-2]\n",
    "    class_names[lab] = class_name\n",
    "    class_num[lab] = len(tr.loc[tr[1] == lab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './log'\n",
    "DATASET = 'plain'\n",
    "MODEL_ID = 'test'\n",
    "DATALOADER_WORKERS = 4\n",
    "LEARNING_RATE = 0.01\n",
    "LR_DECAY_FACTOR = 0.1\n",
    "LR_DECAY_EPOCHS = 10\n",
    "DROPOUT = False\n",
    "DROPOUT_RATE = 0.5\n",
    "MOMENTUM = 0.9\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 256\n",
    "DISPLAY_STEP = 10\n",
    "NUM_CLASSES = 397\n",
    "\n",
    "if not os.path.isdir(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sun_dataset_test (torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__ (self, txt_file, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(txt_file, header=None, sep=' ')\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        \n",
    "        image = Image.open(self.df.iloc[idx, 0])\n",
    "        label = self.df.iloc[idx, 1] - 1\n",
    "#         image_dir = self.df.iloc[idx, 0]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.RandomResizeCrop(224)\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sun_dataset_test(txt_file='./sun397_test_lt.txt', transform=data_transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=DATALOADER_WORKERS)\n",
    "dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./log/model_combine_aug_base_lr_100_ep_150_caffe_drop_0.5_dim_4096_checkpoint.pth.tar')\n",
    "DROPOUT = True\n",
    "DROPOUT_RATE = 0.5\n",
    "FC_ADD_DIM = 4096\n",
    "BIAS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Model using dropout.\n",
      "Bias is True\n",
      "Intermediate fc dimension is: 4096\n",
      "Dropout rate is: 0.500000\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet152(pretrained=True)\n",
    "# Freeze all layers\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print('Done.')    \n",
    "\n",
    "if DROPOUT:\n",
    "    print('Model using dropout.')\n",
    "    resnet = MyResNet(resnet, NUM_CLASSES, DROPOUT_RATE, FC_ADD_DIM, bias=BIAS)\n",
    "else:\n",
    "    print('Model not using dropout.')\n",
    "    # Reset the fc layer\n",
    "    num_features = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(num_features, NUM_CLASSES)\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:06<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.925, accuracy_micro: 0.480, accuracy_macro: 0.480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "running_correct_total = 0\n",
    "\n",
    "class_correct = torch.tensor([0. for i in range(NUM_CLASSES)])\n",
    "class_total = torch.tensor([0. for i in range(NUM_CLASSES)])\n",
    "\n",
    "# Iterate over data\n",
    "for inputs, labels in tqdm(dataloader):\n",
    "\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    # Forward\n",
    "    # If on training phase, enable gradients\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        logits = model(inputs)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        loss = loss_function(logits, labels)\n",
    "    \n",
    "    # Record loss and correct predictions\n",
    "    correct_tensor = (preds == labels).squeeze()\n",
    "    running_loss += loss.item() * inputs.shape[0]\n",
    "    running_correct_total += correct_tensor.sum().item()\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += correct_tensor[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# Epoch loss and accuracieds\n",
    "test_loss = running_loss / dataset_size\n",
    "test_acc_mic = running_correct_total / dataset_size\n",
    "test_acc_mac = (class_correct / class_total).mean().item()\n",
    "\n",
    "print('loss: %.3f, accuracy_micro: %.3f, accuracy_macro: %.3f' \n",
    "      % (test_loss, test_acc_mic, test_acc_mac))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for l in range(len(class_acc)):\n",
    "#     print('class id: %4d,    class name: %25s,    class data number: %5d,    accuracy: %.1f' %(l, class_names[l+1], class_num[l+1], class_acc[l]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plain_base_lr_40_ep_70_caffe_drop_0.5_dim_4096 0.451\n",
    "\n",
    "plain_base_lr_30_ep_70_caffe_drop_0.5_dim_4096 0.448\n",
    "\n",
    "plain_base_lr_30_ep_70_caffe_drop_0.5_dim_4096_zerobias 0.447\n",
    "\n",
    "plain_base_lr_30_ep_70_caffe_drop_0.5_dim_2048 0.444\n",
    "\n",
    "plain_base_lr_30_ep_70_caffe_drop_0.5_dim_1024 0.437\n",
    "\n",
    "\n",
    "\n",
    "plain_base_lr_30_ep_70_caffe_drop_0.3_dim_4096 0.443\n",
    "\n",
    "plain_base_lr_30_ep_70_caffe_drop_0.3_dim_2048 0.445\n",
    "\n",
    "plain_base_lr_30_ep_70_caffe_drop_0.3_dim_1024 0.444\n",
    "\n",
    "\n",
    "plain_base_lr_50_ep_150_caffe_drop_0.5_dim_4096 0.448\n",
    "\n",
    "plain_base_lr_60_ep_150_caffe_drop_0.5_dim_4096 0.452\n",
    "\n",
    "plain_base_lr_70_ep_150_caffe_drop_0.5_dim_4096 0.452\n",
    "\n",
    "plain_base_lr_100_ep_150_caffe_drop_0.5_dim_4096 0.453 113\n",
    "\n",
    "\n",
    "\n",
    "combine_base_lr_70_ep_150_caffe_drop_0.5_dim_4096 0.472 136\n",
    "\n",
    "aug_base_lr_100_ep_150_caffe_drop_0.5_dim_4096 0.457 99\n",
    "\n",
    "combine_aug_sm_base_lr_100_ep_150_caffe_drop_0.5_dim_4096 0.477 126\n",
    "\n",
    "combine_aug_base_lr_100_ep_150_caffe_drop_0.5_dim_4096 0.48 110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python ResNet_SUN397.py --dataset plain --epoch 150 --model_id plain_base_lr_70_ep_150_caffe_drop_0.5_dim_4096 --decay_epoch 70 --caffe_weights True --dropout True --dropout_rate 0.5 --fc_add_dim 4096"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
